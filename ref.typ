#set page(paper: "a4")
#set text(11pt)
#set par(justify: true)

= Row Echelon Form and Gaussian Elimination
Row echelon form (REF) of a matrix can be obtained by using Gaussian 
elimination, it plays significant role in the problem of finding solution with
respect to a linear system. Let's consider the following system of equations
with $n$ variables:
$
cases(
  a_11 x_1 + a_12 x_2 + ... + a_(1n) x_n = b_1\
  a_21 x_1 + a_22 x_2 + ... + a_(2n) x_n = b_2\
    quad quad quad quad quad quad quad dots.v\
  a_(n 1) x_1 + a_(n 2) x_2 + ... + a_(n n) x_n = b_n\
)
$
It can be simplified into matrix form 
$ A x = b $
with 
$
A = mat(
  a_11, a_12, ..., a_1n;
  a_21, a_22, ..., a_2n;
  dots.v, dots.v, dots.down, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n);
), quad
x = mat(
  x_1; x_2; dots.v; x_n;
),quad 
b = mat(
  b_1; b_2; dots.v; b_n;
).
$
== Elementary Row Operations
To solve the system of linear equations, we are perform elementary row 
operations:
+ Swapping two rows:$
mat(
  a_11, a_12, ..., a_1n;
  dots.v, dots.v, dots.down, dots.v;
  a_(i 1), a_(i 2), ..., a_(i n);
  dots.v, dots.v, dots.down, dots.v;
  a_(j 1), a_(j 2), ..., a_(j n);
  dots.v, dots.v, dots.down, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n);
) op(arrow.long, limits: #true)^(r_i^' = r_j, r_j^' = r_i)
mat(
  a_11, a_12, ..., a_1n;
  dots.v, dots.v, dots.down, dots.v;
  a_(j 1), a_(j 2), ..., a_(j n);
  dots.v, dots.v, dots.down, dots.v;
  a_(i 1), a_(i 2), ..., a_(i n);
  dots.v, dots.v, dots.down, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n);
)
$
+ Multiplying a row by a nonzero number:$
mat(
  a_11, a_12, ..., a_1n;
  dots.v, dots.v, dots.down, dots.v;
  a_(i 1), a_(i 2), ..., a_(i n);
  dots.v, dots.v, dots.down, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n);
) op(arrow.long, limits: #true)^(r_i^' = c times r_i)
mat(
  a_11, a_12, ..., a_1n;
  dots.v, dots.v, dots.down, dots.v;
  c times a_(i 1), c times a_(i 2), ..., c times a_(i n);
  dots.v, dots.v, dots.down, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n);
)
$
+ Adding a multiple of one row to another row.$
mat(
  a_11, a_12, ..., a_1n;
  dots.v, dots.v, dots.down, dots.v;
  a_(i 1), a_(i 2), ..., a_(i n);
  dots.v, dots.v, dots.down, dots.v;
  a_(j 1), a_(j 2), ..., a_(j n);
  dots.v, dots.v, dots.down, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n);
) op(arrow.long, limits: #true)^(r_i^' = r_i + c r_j)
mat(
  a_11, a_12, ..., a_1n;
  dots.v, dots.v, dots.down, dots.v;
  a_(i 1) + c a_(j 1), a_(i 2) + c a_(j 2), ..., a_(i n) + c a_(j n);
  dots.v, dots.v, dots.down, dots.v;
  a_(j 1), a_(j 2), ..., a_(j n);
  dots.v, dots.v, dots.down, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n);
)
$
The greatest advantage of elementary row operations is: they *do not change the
solution space of our system of equations*, that is, the set of solutions of REF 
generated by using elementary row operations is identical to the origin system.
== Find REF by Gaussian Elimination
Define the augmented matrix 
$
A = mat(
  a_11, a_12, ..., a_1n, b_1;
  a_21, a_22, ..., a_2n, b_2;
  dots.v, dots.v, dots.down, dots.v, dots.v;
  a_(n 1), a_(n 2), ..., a_(n n), b_n;
  augment: #(vline: -1)
), quad
$
our goal is reduce $A$ to its REF 
$
mat(
  1, 0, ..., 0, s_1;
  0, 1, ..., 0, s_2;
  dots.v, dots.v, dots.down, dots.v, dots.v;
  0, 0, ..., 1, s_n;
  augment: #(vline: -1)
)
$
if possible
#footnote[For more details, see *Appendix*]. 
The solution of our original system $A x = b$ is just 
$
cases(
  x_1 &= s_1\
  x_2 &= s_2\
  &space dots.v\
  x_n &= s_n
)
$
== Example
Lets be more specific, consider the following linear system
$
cases(
  2x_1 + x_2 - x_3 &= 8\
  -3 x_1 - x_2 + 2 x_3 &= -11\
  -2 x_1 + x_2 + 2 x_3 &= -3
)
$
To solve this system, firstly we are going to write it into matrix form:
$
A = mat(
  2, 1, -1;
  -3, -1, 2;
  -2, 1, 2
), quad
x = mat(
  x_1; x_2; x_3;
), quad
b = mat(
  8; -11; 3
).
$
The corresponding augmented matrix is 
$
mat(
  2, 1, -1, 8;
  -3, -1, 2, -11;
  -2, 1, 2, 3;
  augment: #(vline: -1)
)
$
By doing Gaussian elimination, we have
$
mat(
  2, 1, -1, 8;
  -3, -1, 2, -11;
  -2, 1, 2, 3;
  augment: #(vline: -1)
) 
&op(arrow.long, limits: #true)^(r_2^' = r_2 + 3/2 r_j)
mat(
  2, 1, -1, 8;
  0, 1/2, 1/2, 1;
  -2, 1, 2, 3;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_2^' = r_2 + r_1)
mat(
  2, 1, -1, 8;
  0, 1/2, 1/2, 1;
  0, 2, 1, 5;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_3^' = r_3 - 4 r_2)
mat(
  2, 1, -1, 8;
  0, 1/2, 1/2, 1;
  0, 0, -1, 1;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_2^' = r_2 + 1/2 r_3)
mat(
  2, 1, -1, 8;
  0, 1/2, 0, 3/2;
  0, 0, -1, 1;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_1^' = r_1 - r_3)
mat(
  2, 1, 0, 7;
  0, 1/2, 0, 3/2;
  0, 0, -1, 1;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_1^' = r_1 - 2 r_2)
mat(
  2, 0, 0, 4;
  0, 1/2, 0, 3/2;
  0, 0, -1, 1;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_1^' = 1/2 r_1)
mat(
  1, 0, 0, 2;
  0, 1/2, 0, 3/2;
  0, 0, -1, 1;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_2^' = 2 r_2)
mat(
  1, 0, 0, 2;
  0, 1, 0, 3;
  0, 0, -1, 1;
  augment: #(vline: -1))\
&op(arrow.long, limits: #true)^(r_3^' =  -r_3)
mat(
  1, 0, 0, 2;
  0, 1, 0, 3;
  0, 0, 1, -1;
  augment: #(vline: -1))\
$
And this gives us the solution 
$
cases(
  x_1 = 2\
  x_2 = 3\
  x_3 = -1
)
$
= Appendix
We cannot always find a unique set of solutions for arbitrary given linear 
system of equations. You can formally prove that a *consistent* linear system 
with $n$ variables has unique solution if and only if there exists $n$ *linearly
independent* constraints. 

In terms of consistency, consider the following system of equations:
$
cases(
  2x_1 + x_2 - x_3 &= 8\
  -3 x_1 - x_2 + 2 x_3 &= -11\
  -3 x_1 - x_2 + 2 x_3 &= -10\
)
$
Try to find its solution using Gaussian elimination, what tells you that it does
not have solution?

In terms of linearly independent constraints, consider the following system 
of equations:
$
cases(
  2x_1 + x_2 - x_3 &= 8\
  -3 x_1 - x_2 + 2 x_3 &= -11\
  4x_1 + 2x_2 - 2 x_3 &= 16\
)
$
Try to find its solution using Gaussian elimination, this is the case that we
does not provides enough constraints on the system of equation. It turns out 
the system is *consistent* but has *infinity* number of solutions.